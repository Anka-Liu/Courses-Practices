{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as sps\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train_test_final.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_ps_3d_total</th>\n",
       "      <th>card-state_ps_3d_total</th>\n",
       "      <th>card-state_ps_14d_total</th>\n",
       "      <th>card-state_ps_3d_maximum</th>\n",
       "      <th>card-state_ps_1d_total</th>\n",
       "      <th>card-state_ps_7d_maximum</th>\n",
       "      <th>card-state_ps_30d_total</th>\n",
       "      <th>card_ps_0d_total</th>\n",
       "      <th>card-state_ps_1d_maximum</th>\n",
       "      <th>card-merchant_ps_3d_total</th>\n",
       "      <th>...</th>\n",
       "      <th>card-state_ps_14d_average</th>\n",
       "      <th>card-merchant_ps_1d_total</th>\n",
       "      <th>card_ps_30d_average</th>\n",
       "      <th>card-state_ps_7d_median</th>\n",
       "      <th>merch#_ps_3d_total</th>\n",
       "      <th>card-state_ps_0d_maximum</th>\n",
       "      <th>card-state_ps_14d_median</th>\n",
       "      <th>card-state_ps_0d_total</th>\n",
       "      <th>card-state_ps_0d_average</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>0.239431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.057503</td>\n",
       "      <td>0.293871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.423042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.224369</td>\n",
       "      <td>1.608665</td>\n",
       "      <td>0.087707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.481152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3339</th>\n",
       "      <td>0.109461</td>\n",
       "      <td>0.052926</td>\n",
       "      <td>0.122207</td>\n",
       "      <td>0.015794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016556</td>\n",
       "      <td>0.066435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050124</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.582122</td>\n",
       "      <td>0.007515</td>\n",
       "      <td>0.131778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3340</th>\n",
       "      <td>1.303699</td>\n",
       "      <td>0.207725</td>\n",
       "      <td>0.606770</td>\n",
       "      <td>0.452024</td>\n",
       "      <td>0.097819</td>\n",
       "      <td>0.399990</td>\n",
       "      <td>0.455039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357360</td>\n",
       "      <td>0.096802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461099</td>\n",
       "      <td>0.099204</td>\n",
       "      <td>0.328960</td>\n",
       "      <td>0.551246</td>\n",
       "      <td>0.044923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.547433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3341</th>\n",
       "      <td>0.110170</td>\n",
       "      <td>0.054255</td>\n",
       "      <td>0.123333</td>\n",
       "      <td>0.015794</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>0.016556</td>\n",
       "      <td>0.067337</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.005603</td>\n",
       "      <td>0.051484</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002240</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>-0.582219</td>\n",
       "      <td>0.007515</td>\n",
       "      <td>0.132670</td>\n",
       "      <td>0.007521</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0.012225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3342</th>\n",
       "      <td>-0.025350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.013172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.042135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.602674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      card_ps_3d_total  card-state_ps_3d_total  card-state_ps_14d_total  \\\n",
       "3338          0.239431                0.000000                 0.405804   \n",
       "3339          0.109461                0.052926                 0.122207   \n",
       "3340          1.303699                0.207725                 0.606770   \n",
       "3341          0.110170                0.054255                 0.123333   \n",
       "3342         -0.025350                0.000000                -0.013172   \n",
       "\n",
       "      card-state_ps_3d_maximum  card-state_ps_1d_total  \\\n",
       "3338                  0.000000                0.000000   \n",
       "3339                  0.015794                0.000000   \n",
       "3340                  0.452024                0.097819   \n",
       "3341                  0.015794                0.001374   \n",
       "3342                  0.000000                0.000000   \n",
       "\n",
       "      card-state_ps_7d_maximum  card-state_ps_30d_total  card_ps_0d_total  \\\n",
       "3338                  1.057503                 0.293871          0.000000   \n",
       "3339                  0.016556                 0.066435          0.000000   \n",
       "3340                  0.399990                 0.455039          0.000000   \n",
       "3341                  0.016556                 0.067337          0.001415   \n",
       "3342                  0.000000                -0.042135          0.000000   \n",
       "\n",
       "      card-state_ps_1d_maximum  card-merchant_ps_3d_total  ...  \\\n",
       "3338                  0.000000                   0.000000  ...   \n",
       "3339                  0.000000                   0.050124  ...   \n",
       "3340                  0.357360                   0.096802  ...   \n",
       "3341                  0.005603                   0.051484  ...   \n",
       "3342                  0.000000                   0.000000  ...   \n",
       "\n",
       "      card-state_ps_14d_average  card-merchant_ps_1d_total  \\\n",
       "3338                   1.423042                   0.000000   \n",
       "3339                  -0.002238                   0.000000   \n",
       "3340                   0.461099                   0.099204   \n",
       "3341                  -0.002240                   0.001394   \n",
       "3342                  -0.010154                   0.000000   \n",
       "\n",
       "      card_ps_30d_average  card-state_ps_7d_median  merch#_ps_3d_total  \\\n",
       "3338             0.224369                 1.608665            0.087707   \n",
       "3339            -0.582122                 0.007515            0.131778   \n",
       "3340             0.328960                 0.551246            0.044923   \n",
       "3341            -0.582219                 0.007515            0.132670   \n",
       "3342            -0.602674                 0.000000            0.004678   \n",
       "\n",
       "      card-state_ps_0d_maximum  card-state_ps_14d_median  \\\n",
       "3338                  0.000000                  1.481152   \n",
       "3339                  0.000000                  0.000110   \n",
       "3340                  0.000000                  0.547433   \n",
       "3341                  0.007521                  0.000110   \n",
       "3342                  0.000000                 -0.006842   \n",
       "\n",
       "      card-state_ps_0d_total  card-state_ps_0d_average  fraud  \n",
       "3338                0.000000                  0.000000      0  \n",
       "3339                0.000000                  0.000000      0  \n",
       "3340                0.000000                  0.000000      0  \n",
       "3341                0.002375                  0.012225      0  \n",
       "3342                0.000000                  0.000000      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_ps_3d_total              float64\n",
       "card-state_ps_3d_total        float64\n",
       "card-state_ps_14d_total       float64\n",
       "card-state_ps_3d_maximum      float64\n",
       "card-state_ps_1d_total        float64\n",
       "card-state_ps_7d_maximum      float64\n",
       "card-state_ps_30d_total       float64\n",
       "card_ps_0d_total              float64\n",
       "card-state_ps_1d_maximum      float64\n",
       "card-merchant_ps_3d_total     float64\n",
       "card_ps_0d_maximum            float64\n",
       "card-state_ps_3d_average      float64\n",
       "card-state_ps_1d_average      float64\n",
       "card-state_ps_1d_median       float64\n",
       "card-zip_ps_30d_total         float64\n",
       "card-state_ps_7d_average      float64\n",
       "card-zip_ps_3d_maximum        float64\n",
       "card-state_ps_3d_median       float64\n",
       "card-merchant_ps_30d_total    float64\n",
       "card-zip_ps_1d_total          float64\n",
       "card-zip_ps_1d_maximum        float64\n",
       "card-state_ps_14d_average     float64\n",
       "card-merchant_ps_1d_total     float64\n",
       "card_ps_30d_average           float64\n",
       "card-state_ps_7d_median       float64\n",
       "merch#_ps_3d_total            float64\n",
       "card-state_ps_0d_maximum      float64\n",
       "card-state_ps_14d_median      float64\n",
       "card-state_ps_0d_total        float64\n",
       "card-state_ps_0d_average      float64\n",
       "fraud                           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In training set, with 5 nodes and 0.01 alpha, FDR at 3%: 0.6942857142857143\n",
      "In testing set, with 5 nodes and 0.01 alpha, FDR at 3%: 0.710204081632653\n",
      "In training set, with 6 nodes and 0.01 alpha, FDR at 3%: 0.7150649350649351\n",
      "In testing set, with 6 nodes and 0.01 alpha, FDR at 3%: 0.7163265306122448\n",
      "In training set, with 7 nodes and 0.01 alpha, FDR at 3%: 0.7023376623376623\n",
      "In testing set, with 7 nodes and 0.01 alpha, FDR at 3%: 0.7244897959183673\n",
      "In training set, with 8 nodes and 0.01 alpha, FDR at 3%: 0.7038961038961039\n",
      "In testing set, with 8 nodes and 0.01 alpha, FDR at 3%: 0.7061224489795918\n",
      "In training set, with 9 nodes and 0.01 alpha, FDR at 3%: 0.6966233766233766\n",
      "In testing set, with 9 nodes and 0.01 alpha, FDR at 3%: 0.6959183673469388\n",
      "In training set, with 10 nodes and 0.01 alpha, FDR at 3%: 0.7218181818181819\n",
      "In testing set, with 10 nodes and 0.01 alpha, FDR at 3%: 0.7326530612244898\n",
      "In training set, with 11 nodes and 0.01 alpha, FDR at 3%: 0.7277922077922079\n",
      "In testing set, with 11 nodes and 0.01 alpha, FDR at 3%: 0.7244897959183673\n",
      "In training set, with 12 nodes and 0.01 alpha, FDR at 3%: 0.7449350649350649\n",
      "In testing set, with 12 nodes and 0.01 alpha, FDR at 3%: 0.7387755102040817\n",
      "In training set, with 13 nodes and 0.01 alpha, FDR at 3%: 0.7384415584415585\n",
      "In testing set, with 13 nodes and 0.01 alpha, FDR at 3%: 0.7489795918367348\n",
      "In training set, with 14 nodes and 0.01 alpha, FDR at 3%: 0.7548051948051948\n",
      "In testing set, with 14 nodes and 0.01 alpha, FDR at 3%: 0.763265306122449\n",
      "In training set, with 15 nodes and 0.01 alpha, FDR at 3%: 0.730909090909091\n",
      "In testing set, with 15 nodes and 0.01 alpha, FDR at 3%: 0.7183673469387756\n",
      "In training set, with 16 nodes and 0.01 alpha, FDR at 3%: 0.7597402597402597\n",
      "In testing set, with 16 nodes and 0.01 alpha, FDR at 3%: 0.7551020408163266\n",
      "In training set, with 17 nodes and 0.01 alpha, FDR at 3%: 0.7467532467532467\n",
      "In testing set, with 17 nodes and 0.01 alpha, FDR at 3%: 0.7653061224489796\n",
      "In training set, with 18 nodes and 0.01 alpha, FDR at 3%: 0.7454545454545455\n",
      "In testing set, with 18 nodes and 0.01 alpha, FDR at 3%: 0.7469387755102042\n",
      "In training set, with 19 nodes and 0.01 alpha, FDR at 3%: 0.7555844155844156\n",
      "In testing set, with 19 nodes and 0.01 alpha, FDR at 3%: 0.7530612244897957\n",
      "In training set, with 20 nodes and 0.01 alpha, FDR at 3%: 0.7579220779220779\n",
      "In testing set, with 20 nodes and 0.01 alpha, FDR at 3%: 0.7551020408163265\n"
     ]
    }
   ],
   "source": [
    "# hidden_layer_size range(5,21,1) & alpha = 0.01\n",
    "\n",
    "for n in range(5,21,1):\n",
    "    fdr_train = 0\n",
    "    fdr_test = 0\n",
    "\n",
    "    for i in range(5):\n",
    "        \n",
    "        kfolds = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "        for train_index, test_index in kfolds.split(data):\n",
    "            y_train = data.iloc[train_index, -1].to_numpy()\n",
    "            y_test = data.iloc[test_index, -1].to_numpy()\n",
    "            x_train = data.iloc[train_index, 0:-1].to_numpy()\n",
    "            x_test = data.iloc[test_index, 0:-1].to_numpy()\n",
    "        \n",
    "        NN = MLPClassifier(\n",
    "            hidden_layer_sizes=(n,),\n",
    "            activation='relu',\n",
    "            learning_rate='adaptive',\n",
    "            max_iter=10000,\n",
    "            learning_rate_init=.01,\n",
    "            alpha=.01)\n",
    "        \n",
    "        NN.fit(x_train,y_train)\n",
    "        \n",
    "        NN_train_pred = NN.predict_proba(x_train)[:,1]\n",
    "        ind = np.argsort(NN_train_pred)\n",
    "        NN_y_train_sorted = np.take_along_axis(y_train, ind, axis=0)\n",
    "        NN_train_pred_sorted = np.take_along_axis(NN_train_pred, ind, axis=0)\n",
    "        NN_y_train_sorted_3per = NN_y_train_sorted[-int(len(NN_y_train_sorted)*0.03):-1]\n",
    "        NN_y_train_sorted_3per_fraud = NN_y_train_sorted_3per[NN_y_train_sorted_3per==1]\n",
    "        y_train_fraud = len(y_train[y_train==1])\n",
    "        fdr_train += len(NN_y_train_sorted_3per_fraud)/y_train_fraud\n",
    "\n",
    "        NN_test_pred = NN.predict_proba(x_test)[:,1]\n",
    "        ind = np.argsort(NN_test_pred)\n",
    "        NN_y_test_sorted = np.take_along_axis(y_test, ind, axis=0)\n",
    "        NN_test_pred_sorted = np.take_along_axis(NN_test_pred, ind, axis=0)\n",
    "        NN_y_test_sorted_3per = NN_y_test_sorted[-int(len(NN_y_test_sorted)*0.03):-1]\n",
    "        NN_y_test_sorted_3per_fraud = NN_y_test_sorted_3per[NN_y_test_sorted_3per==1]\n",
    "        y_test_fraud = len(y_test[y_test==1])\n",
    "        fdr_test += len(NN_y_test_sorted_3per_fraud)/y_test_fraud\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    avg_fdr_train = fdr_train/5\n",
    "    avg_fdr_test = fdr_test/5\n",
    "\n",
    "    print(f'In training set, with {n} nodes and 0.01 alpha, FDR at 3%:', avg_fdr_train)\n",
    "    print(f'In testing set, with {n} nodes and 0.01 alpha, FDR at 3%:', avg_fdr_test)\n",
    "    \n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In training set, with 5 nodes and 0.05 alpha, FDR at 3%: 0.6625974025974026\n",
      "In testing set, with 5 nodes and 0.05 alpha, FDR at 3%: 0.6755102040816326\n",
      "In training set, with 6 nodes and 0.05 alpha, FDR at 3%: 0.6618181818181819\n",
      "In testing set, with 6 nodes and 0.05 alpha, FDR at 3%: 0.6755102040816326\n",
      "In training set, with 7 nodes and 0.05 alpha, FDR at 3%: 0.6688311688311688\n",
      "In testing set, with 7 nodes and 0.05 alpha, FDR at 3%: 0.6795918367346939\n",
      "In training set, with 8 nodes and 0.05 alpha, FDR at 3%: 0.6667532467532468\n",
      "In testing set, with 8 nodes and 0.05 alpha, FDR at 3%: 0.6816326530612244\n",
      "In training set, with 9 nodes and 0.05 alpha, FDR at 3%: 0.6735064935064935\n",
      "In testing set, with 9 nodes and 0.05 alpha, FDR at 3%: 0.7061224489795919\n",
      "In training set, with 10 nodes and 0.05 alpha, FDR at 3%: 0.6701298701298701\n",
      "In testing set, with 10 nodes and 0.05 alpha, FDR at 3%: 0.6775510204081633\n",
      "In training set, with 11 nodes and 0.05 alpha, FDR at 3%: 0.6797402597402598\n",
      "In testing set, with 11 nodes and 0.05 alpha, FDR at 3%: 0.7\n",
      "In training set, with 12 nodes and 0.05 alpha, FDR at 3%: 0.678961038961039\n",
      "In testing set, with 12 nodes and 0.05 alpha, FDR at 3%: 0.6857142857142857\n",
      "In training set, with 13 nodes and 0.05 alpha, FDR at 3%: 0.6792207792207792\n",
      "In testing set, with 13 nodes and 0.05 alpha, FDR at 3%: 0.7081632653061224\n",
      "In training set, with 14 nodes and 0.05 alpha, FDR at 3%: 0.6683116883116883\n",
      "In testing set, with 14 nodes and 0.05 alpha, FDR at 3%: 0.6816326530612244\n",
      "In training set, with 15 nodes and 0.05 alpha, FDR at 3%: 0.681038961038961\n",
      "In testing set, with 15 nodes and 0.05 alpha, FDR at 3%: 0.6979591836734695\n",
      "In training set, with 16 nodes and 0.05 alpha, FDR at 3%: 0.6799999999999999\n",
      "In testing set, with 16 nodes and 0.05 alpha, FDR at 3%: 0.7020408163265306\n",
      "In training set, with 17 nodes and 0.05 alpha, FDR at 3%: 0.681038961038961\n",
      "In testing set, with 17 nodes and 0.05 alpha, FDR at 3%: 0.7020408163265306\n",
      "In training set, with 18 nodes and 0.05 alpha, FDR at 3%: 0.6797402597402598\n",
      "In testing set, with 18 nodes and 0.05 alpha, FDR at 3%: 0.6816326530612244\n",
      "In training set, with 19 nodes and 0.05 alpha, FDR at 3%: 0.6841558441558442\n",
      "In testing set, with 19 nodes and 0.05 alpha, FDR at 3%: 0.7040816326530612\n",
      "In training set, with 20 nodes and 0.05 alpha, FDR at 3%: 0.6742857142857143\n",
      "In testing set, with 20 nodes and 0.05 alpha, FDR at 3%: 0.6938775510204082\n"
     ]
    }
   ],
   "source": [
    "# hidden_layer_size range(5,21,1) & alpha = 0.05\n",
    "\n",
    "for n in range(5,21,1):\n",
    "    fdr_train = 0\n",
    "    fdr_test = 0\n",
    "\n",
    "    for i in range(5):\n",
    "        \n",
    "        kfolds = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "        for train_index, test_index in kfolds.split(data):\n",
    "            y_train = data.iloc[train_index, -1].to_numpy()\n",
    "            y_test = data.iloc[test_index, -1].to_numpy()\n",
    "            x_train = data.iloc[train_index, 0:-1].to_numpy()\n",
    "            x_test = data.iloc[test_index, 0:-1].to_numpy()\n",
    "        \n",
    "        NN = MLPClassifier(\n",
    "            hidden_layer_sizes=(n,),\n",
    "            activation='relu',\n",
    "            learning_rate='adaptive',\n",
    "            max_iter=10000,\n",
    "            learning_rate_init=.01,\n",
    "            alpha=.05)\n",
    "        \n",
    "        NN.fit(x_train,y_train)\n",
    "        \n",
    "        NN_train_pred = NN.predict_proba(x_train)[:,1]\n",
    "        ind = np.argsort(NN_train_pred)\n",
    "        NN_y_train_sorted = np.take_along_axis(y_train, ind, axis=0)\n",
    "        NN_train_pred_sorted = np.take_along_axis(NN_train_pred, ind, axis=0)\n",
    "        NN_y_train_sorted_3per = NN_y_train_sorted[-int(len(NN_y_train_sorted)*0.03):-1]\n",
    "        NN_y_train_sorted_3per_fraud = NN_y_train_sorted_3per[NN_y_train_sorted_3per==1]\n",
    "        y_train_fraud = len(y_train[y_train==1])\n",
    "        fdr_train += len(NN_y_train_sorted_3per_fraud)/y_train_fraud\n",
    "    \n",
    "        NN_test_pred = NN.predict_proba(x_test)[:,1]\n",
    "        ind = np.argsort(NN_test_pred)\n",
    "        NN_y_test_sorted = np.take_along_axis(y_test, ind, axis=0)\n",
    "        NN_test_pred_sorted = np.take_along_axis(NN_test_pred, ind, axis=0)\n",
    "        NN_y_test_sorted_3per = NN_y_test_sorted[-int(len(NN_y_test_sorted)*0.03):-1]\n",
    "        NN_y_test_sorted_3per_fraud = NN_y_test_sorted_3per[NN_y_test_sorted_3per==1]\n",
    "        y_test_fraud = len(y_test[y_test==1])\n",
    "        fdr_test += len(NN_y_test_sorted_3per_fraud)/y_test_fraud\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    avg_fdr_train = fdr_train/5\n",
    "    avg_fdr_test = fdr_test/5\n",
    "\n",
    "    print(f'In training set, with {n} nodes and 0.05 alpha, FDR at 3%:', avg_fdr_train)\n",
    "    print(f'In testing set, with {n} nodes and 0.05 alpha, FDR at 3%:', avg_fdr_test)\n",
    "    \n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In training set, with 5 nodes and 0.1 alpha, FDR at 3%: 0.6592207792207792\n",
      "In testing set, with 5 nodes and 0.1 alpha, FDR at 3%: 0.6653061224489796\n",
      "In training set, with 6 nodes and 0.1 alpha, FDR at 3%: 0.6610389610389611\n",
      "In testing set, with 6 nodes and 0.1 alpha, FDR at 3%: 0.6714285714285715\n",
      "In training set, with 7 nodes and 0.1 alpha, FDR at 3%: 0.6550649350649351\n",
      "In testing set, with 7 nodes and 0.1 alpha, FDR at 3%: 0.6714285714285714\n",
      "In training set, with 8 nodes and 0.1 alpha, FDR at 3%: 0.6566233766233767\n",
      "In testing set, with 8 nodes and 0.1 alpha, FDR at 3%: 0.6693877551020408\n",
      "In training set, with 9 nodes and 0.1 alpha, FDR at 3%: 0.6592207792207792\n",
      "In testing set, with 9 nodes and 0.1 alpha, FDR at 3%: 0.6755102040816326\n",
      "In training set, with 10 nodes and 0.1 alpha, FDR at 3%: 0.6587012987012987\n",
      "In testing set, with 10 nodes and 0.1 alpha, FDR at 3%: 0.6775510204081632\n",
      "In training set, with 11 nodes and 0.1 alpha, FDR at 3%: 0.6584415584415584\n",
      "In testing set, with 11 nodes and 0.1 alpha, FDR at 3%: 0.6877551020408162\n",
      "In training set, with 12 nodes and 0.1 alpha, FDR at 3%: 0.665974025974026\n",
      "In testing set, with 12 nodes and 0.1 alpha, FDR at 3%: 0.6857142857142857\n",
      "In training set, with 13 nodes and 0.1 alpha, FDR at 3%: 0.6620779220779222\n",
      "In testing set, with 13 nodes and 0.1 alpha, FDR at 3%: 0.6795918367346939\n",
      "In training set, with 14 nodes and 0.1 alpha, FDR at 3%: 0.6612987012987014\n",
      "In testing set, with 14 nodes and 0.1 alpha, FDR at 3%: 0.6755102040816328\n",
      "In training set, with 15 nodes and 0.1 alpha, FDR at 3%: 0.6641558441558442\n",
      "In testing set, with 15 nodes and 0.1 alpha, FDR at 3%: 0.6836734693877551\n",
      "In training set, with 16 nodes and 0.1 alpha, FDR at 3%: 0.6620779220779222\n",
      "In testing set, with 16 nodes and 0.1 alpha, FDR at 3%: 0.6755102040816328\n",
      "In training set, with 17 nodes and 0.1 alpha, FDR at 3%: 0.6644155844155846\n",
      "In testing set, with 17 nodes and 0.1 alpha, FDR at 3%: 0.6857142857142857\n",
      "In training set, with 18 nodes and 0.1 alpha, FDR at 3%: 0.6600000000000001\n",
      "In testing set, with 18 nodes and 0.1 alpha, FDR at 3%: 0.6673469387755102\n",
      "In training set, with 19 nodes and 0.1 alpha, FDR at 3%: 0.6620779220779222\n",
      "In testing set, with 19 nodes and 0.1 alpha, FDR at 3%: 0.673469387755102\n",
      "In training set, with 20 nodes and 0.1 alpha, FDR at 3%: 0.6599999999999999\n",
      "In testing set, with 20 nodes and 0.1 alpha, FDR at 3%: 0.6877551020408162\n"
     ]
    }
   ],
   "source": [
    "# hidden_layer_size range(5,21,1) & alpha = 0.1\n",
    "\n",
    "for n in range(5,21,1):\n",
    "    fdr_train = 0\n",
    "    fdr_test = 0\n",
    "\n",
    "    for i in range(5):\n",
    "        \n",
    "        kfolds = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "        for train_index, test_index in kfolds.split(data):\n",
    "            y_train = data.iloc[train_index, -1].to_numpy()\n",
    "            y_test = data.iloc[test_index, -1].to_numpy()\n",
    "            x_train = data.iloc[train_index, 0:-1].to_numpy()\n",
    "            x_test = data.iloc[test_index, 0:-1].to_numpy()\n",
    "        \n",
    "        NN = MLPClassifier(\n",
    "            hidden_layer_sizes=(n,),\n",
    "            activation='relu',\n",
    "            learning_rate='adaptive',\n",
    "            max_iter=10000,\n",
    "            learning_rate_init=.01,\n",
    "            alpha=.1)\n",
    "        \n",
    "        NN.fit(x_train,y_train)\n",
    "        \n",
    "        NN_train_pred = NN.predict_proba(x_train)[:,1]\n",
    "        ind = np.argsort(NN_train_pred)\n",
    "        NN_y_train_sorted = np.take_along_axis(y_train, ind, axis=0)\n",
    "        NN_train_pred_sorted = np.take_along_axis(NN_train_pred, ind, axis=0)\n",
    "        NN_y_train_sorted_3per = NN_y_train_sorted[-int(len(NN_y_train_sorted)*0.03):-1]\n",
    "        NN_y_train_sorted_3per_fraud = NN_y_train_sorted_3per[NN_y_train_sorted_3per==1]\n",
    "        y_train_fraud = len(y_train[y_train==1])\n",
    "        fdr_train += len(NN_y_train_sorted_3per_fraud)/y_train_fraud\n",
    "    \n",
    "        NN_test_pred = NN.predict_proba(x_test)[:,1]\n",
    "        ind = np.argsort(NN_test_pred)\n",
    "        NN_y_test_sorted = np.take_along_axis(y_test, ind, axis=0)\n",
    "        NN_test_pred_sorted = np.take_along_axis(NN_test_pred, ind, axis=0)\n",
    "        NN_y_test_sorted_3per = NN_y_test_sorted[-int(len(NN_y_test_sorted)*0.03):-1]\n",
    "        NN_y_test_sorted_3per_fraud = NN_y_test_sorted_3per[NN_y_test_sorted_3per==1]\n",
    "        y_test_fraud = len(y_test[y_test==1])\n",
    "        fdr_test += len(NN_y_test_sorted_3per_fraud)/y_test_fraud\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    avg_fdr_train = fdr_train/5\n",
    "    avg_fdr_test = fdr_test/5\n",
    "\n",
    "    print(f'In training set, with {n} nodes and 0.1 alpha, FDR at 3%:', avg_fdr_train)\n",
    "    print(f'In testing set, with {n} nodes and 0.1 alpha, FDR at 3%:', avg_fdr_test)\n",
    "    \n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In training set, with 5 nodes and 0.02 alpha, FDR at 3%: 0.6799999999999999\n",
      "In testing set, with 5 nodes and 0.02 alpha, FDR at 3%: 0.689795918367347\n",
      "In training set, with 6 nodes and 0.02 alpha, FDR at 3%: 0.6610389610389611\n",
      "In testing set, with 6 nodes and 0.02 alpha, FDR at 3%: 0.6632653061224489\n",
      "In training set, with 7 nodes and 0.02 alpha, FDR at 3%: 0.692987012987013\n",
      "In testing set, with 7 nodes and 0.02 alpha, FDR at 3%: 0.6877551020408164\n",
      "In training set, with 8 nodes and 0.02 alpha, FDR at 3%: 0.6903896103896103\n",
      "In testing set, with 8 nodes and 0.02 alpha, FDR at 3%: 0.7\n",
      "In training set, with 9 nodes and 0.02 alpha, FDR at 3%: 0.6953246753246753\n",
      "In testing set, with 9 nodes and 0.02 alpha, FDR at 3%: 0.7040816326530612\n",
      "In training set, with 10 nodes and 0.02 alpha, FDR at 3%: 0.7057142857142857\n",
      "In testing set, with 10 nodes and 0.02 alpha, FDR at 3%: 0.7183673469387755\n",
      "In training set, with 11 nodes and 0.02 alpha, FDR at 3%: 0.6903896103896103\n",
      "In testing set, with 11 nodes and 0.02 alpha, FDR at 3%: 0.7061224489795919\n",
      "In training set, with 12 nodes and 0.02 alpha, FDR at 3%: 0.7020779220779222\n",
      "In testing set, with 12 nodes and 0.02 alpha, FDR at 3%: 0.7020408163265307\n",
      "In training set, with 13 nodes and 0.02 alpha, FDR at 3%: 0.718181818181818\n",
      "In testing set, with 13 nodes and 0.02 alpha, FDR at 3%: 0.7244897959183675\n",
      "In training set, with 14 nodes and 0.02 alpha, FDR at 3%: 0.7218181818181818\n",
      "In testing set, with 14 nodes and 0.02 alpha, FDR at 3%: 0.7387755102040817\n",
      "In training set, with 15 nodes and 0.02 alpha, FDR at 3%: 0.7038961038961039\n",
      "In testing set, with 15 nodes and 0.02 alpha, FDR at 3%: 0.6877551020408164\n",
      "In training set, with 16 nodes and 0.02 alpha, FDR at 3%: 0.7075324675324675\n",
      "In testing set, with 16 nodes and 0.02 alpha, FDR at 3%: 0.7183673469387755\n",
      "In training set, with 17 nodes and 0.02 alpha, FDR at 3%: 0.7288311688311688\n",
      "In testing set, with 17 nodes and 0.02 alpha, FDR at 3%: 0.7285714285714284\n",
      "In training set, with 18 nodes and 0.02 alpha, FDR at 3%: 0.7127272727272727\n",
      "In testing set, with 18 nodes and 0.02 alpha, FDR at 3%: 0.7204081632653061\n",
      "In training set, with 19 nodes and 0.02 alpha, FDR at 3%: 0.7096103896103896\n",
      "In testing set, with 19 nodes and 0.02 alpha, FDR at 3%: 0.7163265306122449\n",
      "In training set, with 20 nodes and 0.02 alpha, FDR at 3%: 0.7225974025974026\n",
      "In testing set, with 20 nodes and 0.02 alpha, FDR at 3%: 0.7163265306122449\n"
     ]
    }
   ],
   "source": [
    "# hidden_layer_size range(5,21,1) & alpha = 0.02\n",
    "\n",
    "for n in range(5,21,1):\n",
    "    fdr_train = 0\n",
    "    fdr_test = 0\n",
    "\n",
    "    for i in range(5):\n",
    "        \n",
    "        kfolds = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "        for train_index, test_index in kfolds.split(data):\n",
    "            y_train = data.iloc[train_index, -1].to_numpy()\n",
    "            y_test = data.iloc[test_index, -1].to_numpy()\n",
    "            x_train = data.iloc[train_index, 0:-1].to_numpy()\n",
    "            x_test = data.iloc[test_index, 0:-1].to_numpy()\n",
    "        \n",
    "        NN = MLPClassifier(\n",
    "            hidden_layer_sizes=(n,),\n",
    "            activation='relu',\n",
    "            learning_rate='adaptive',\n",
    "            max_iter=10000,\n",
    "            learning_rate_init=.01,\n",
    "            alpha=.02)\n",
    "        \n",
    "        NN.fit(x_train,y_train)\n",
    "        \n",
    "        NN_train_pred = NN.predict_proba(x_train)[:,1]\n",
    "        ind = np.argsort(NN_train_pred)\n",
    "        NN_y_train_sorted = np.take_along_axis(y_train, ind, axis=0)\n",
    "        NN_train_pred_sorted = np.take_along_axis(NN_train_pred, ind, axis=0)\n",
    "        NN_y_train_sorted_3per = NN_y_train_sorted[-int(len(NN_y_train_sorted)*0.03):-1]\n",
    "        NN_y_train_sorted_3per_fraud = NN_y_train_sorted_3per[NN_y_train_sorted_3per==1]\n",
    "        y_train_fraud = len(y_train[y_train==1])\n",
    "        fdr_train += len(NN_y_train_sorted_3per_fraud)/y_train_fraud\n",
    "    \n",
    "        NN_test_pred = NN.predict_proba(x_test)[:,1]\n",
    "        ind = np.argsort(NN_test_pred)\n",
    "        NN_y_test_sorted = np.take_along_axis(y_test, ind, axis=0)\n",
    "        NN_test_pred_sorted = np.take_along_axis(NN_test_pred, ind, axis=0)\n",
    "        NN_y_test_sorted_3per = NN_y_test_sorted[-int(len(NN_y_test_sorted)*0.03):-1]\n",
    "        NN_y_test_sorted_3per_fraud = NN_y_test_sorted_3per[NN_y_test_sorted_3per==1]\n",
    "        y_test_fraud = len(y_test[y_test==1])\n",
    "        fdr_test += len(NN_y_test_sorted_3per_fraud)/y_test_fraud\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    avg_fdr_train = fdr_train/5\n",
    "    avg_fdr_test = fdr_test/5\n",
    "\n",
    "    print(f'In training set, with {n} nodes and 0.02 alpha, FDR at 3%:', avg_fdr_train)\n",
    "    print(f'In testing set, with {n} nodes and 0.02 alpha, FDR at 3%:', avg_fdr_test)\n",
    "    \n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In training set, with 5 nodes and 0.04 alpha, FDR at 3%: 0.6672727272727274\n",
      "In testing set, with 5 nodes and 0.04 alpha, FDR at 3%: 0.673469387755102\n",
      "In training set, with 6 nodes and 0.04 alpha, FDR at 3%: 0.67012987012987\n",
      "In testing set, with 6 nodes and 0.04 alpha, FDR at 3%: 0.6979591836734694\n",
      "In training set, with 7 nodes and 0.04 alpha, FDR at 3%: 0.677142857142857\n",
      "In testing set, with 7 nodes and 0.04 alpha, FDR at 3%: 0.7\n",
      "In training set, with 8 nodes and 0.04 alpha, FDR at 3%: 0.6748051948051947\n",
      "In testing set, with 8 nodes and 0.04 alpha, FDR at 3%: 0.6857142857142857\n",
      "In training set, with 9 nodes and 0.04 alpha, FDR at 3%: 0.6729870129870129\n",
      "In testing set, with 9 nodes and 0.04 alpha, FDR at 3%: 0.6979591836734694\n",
      "In training set, with 10 nodes and 0.04 alpha, FDR at 3%: 0.6787012987012987\n",
      "In testing set, with 10 nodes and 0.04 alpha, FDR at 3%: 0.7020408163265305\n",
      "In training set, with 11 nodes and 0.04 alpha, FDR at 3%: 0.6779220779220779\n",
      "In testing set, with 11 nodes and 0.04 alpha, FDR at 3%: 0.6897959183673469\n",
      "In training set, with 12 nodes and 0.04 alpha, FDR at 3%: 0.675064935064935\n",
      "In testing set, with 12 nodes and 0.04 alpha, FDR at 3%: 0.6775510204081633\n",
      "In training set, with 13 nodes and 0.04 alpha, FDR at 3%: 0.6916883116883117\n",
      "In testing set, with 13 nodes and 0.04 alpha, FDR at 3%: 0.7040816326530612\n",
      "In training set, with 14 nodes and 0.04 alpha, FDR at 3%: 0.665974025974026\n",
      "In testing set, with 14 nodes and 0.04 alpha, FDR at 3%: 0.673469387755102\n",
      "In training set, with 15 nodes and 0.04 alpha, FDR at 3%: 0.6857142857142857\n",
      "In testing set, with 15 nodes and 0.04 alpha, FDR at 3%: 0.6795918367346939\n",
      "In training set, with 16 nodes and 0.04 alpha, FDR at 3%: 0.6768831168831169\n",
      "In testing set, with 16 nodes and 0.04 alpha, FDR at 3%: 0.7142857142857142\n",
      "In training set, with 17 nodes and 0.04 alpha, FDR at 3%: 0.6794805194805195\n",
      "In testing set, with 17 nodes and 0.04 alpha, FDR at 3%: 0.7040816326530612\n",
      "In training set, with 18 nodes and 0.04 alpha, FDR at 3%: 0.688051948051948\n",
      "In testing set, with 18 nodes and 0.04 alpha, FDR at 3%: 0.7\n",
      "In training set, with 19 nodes and 0.04 alpha, FDR at 3%: 0.6888311688311688\n",
      "In testing set, with 19 nodes and 0.04 alpha, FDR at 3%: 0.7\n",
      "In training set, with 20 nodes and 0.04 alpha, FDR at 3%: 0.6836363636363636\n",
      "In testing set, with 20 nodes and 0.04 alpha, FDR at 3%: 0.7\n"
     ]
    }
   ],
   "source": [
    "# hidden_layer_size range(5,21,1) & alpha = 0.04\n",
    "\n",
    "for n in range(5,21,1):\n",
    "    fdr_train = 0\n",
    "    fdr_test = 0\n",
    "\n",
    "    for i in range(5):\n",
    "        \n",
    "        kfolds = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "        for train_index, test_index in kfolds.split(data):\n",
    "            y_train = data.iloc[train_index, -1].to_numpy()\n",
    "            y_test = data.iloc[test_index, -1].to_numpy()\n",
    "            x_train = data.iloc[train_index, 0:-1].to_numpy()\n",
    "            x_test = data.iloc[test_index, 0:-1].to_numpy()\n",
    "        \n",
    "        NN = MLPClassifier(\n",
    "            hidden_layer_sizes=(n,),\n",
    "            activation='relu',\n",
    "            learning_rate='adaptive',\n",
    "            max_iter=10000,\n",
    "            learning_rate_init=.01,\n",
    "            alpha=.04)\n",
    "        \n",
    "        NN.fit(x_train,y_train)\n",
    "        \n",
    "        NN_train_pred = NN.predict_proba(x_train)[:,1]\n",
    "        ind = np.argsort(NN_train_pred)\n",
    "        NN_y_train_sorted = np.take_along_axis(y_train, ind, axis=0)\n",
    "        NN_train_pred_sorted = np.take_along_axis(NN_train_pred, ind, axis=0)\n",
    "        NN_y_train_sorted_3per = NN_y_train_sorted[-int(len(NN_y_train_sorted)*0.03):-1]\n",
    "        NN_y_train_sorted_3per_fraud = NN_y_train_sorted_3per[NN_y_train_sorted_3per==1]\n",
    "        y_train_fraud = len(y_train[y_train==1])\n",
    "        fdr_train += len(NN_y_train_sorted_3per_fraud)/y_train_fraud\n",
    "    \n",
    "        NN_test_pred = NN.predict_proba(x_test)[:,1]\n",
    "        ind = np.argsort(NN_test_pred)\n",
    "        NN_y_test_sorted = np.take_along_axis(y_test, ind, axis=0)\n",
    "        NN_test_pred_sorted = np.take_along_axis(NN_test_pred, ind, axis=0)\n",
    "        NN_y_test_sorted_3per = NN_y_test_sorted[-int(len(NN_y_test_sorted)*0.03):-1]\n",
    "        NN_y_test_sorted_3per_fraud = NN_y_test_sorted_3per[NN_y_test_sorted_3per==1]\n",
    "        y_test_fraud = len(y_test[y_test==1])\n",
    "        fdr_test += len(NN_y_test_sorted_3per_fraud)/y_test_fraud\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    avg_fdr_train = fdr_train/5\n",
    "    avg_fdr_test = fdr_test/5\n",
    "\n",
    "    print(f'In training set, with {n} nodes and 0.04 alpha, FDR at 3%:', avg_fdr_train)\n",
    "    print(f'In testing set, with {n} nodes and 0.04 alpha, FDR at 3%:', avg_fdr_test)\n",
    "    \n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In training set, with 5 nodes and 0.06 alpha, FDR at 3%: 0.6633766233766233\n",
      "In testing set, with 5 nodes and 0.06 alpha, FDR at 3%: 0.689795918367347\n",
      "In training set, with 6 nodes and 0.06 alpha, FDR at 3%: 0.6615584415584416\n",
      "In testing set, with 6 nodes and 0.06 alpha, FDR at 3%: 0.6714285714285714\n",
      "In training set, with 7 nodes and 0.06 alpha, FDR at 3%: 0.6766233766233767\n",
      "In testing set, with 7 nodes and 0.06 alpha, FDR at 3%: 0.6857142857142857\n",
      "In training set, with 8 nodes and 0.06 alpha, FDR at 3%: 0.6688311688311688\n",
      "In testing set, with 8 nodes and 0.06 alpha, FDR at 3%: 0.6734693877551019\n",
      "In training set, with 9 nodes and 0.06 alpha, FDR at 3%: 0.6727272727272726\n",
      "In testing set, with 9 nodes and 0.06 alpha, FDR at 3%: 0.6795918367346938\n",
      "In training set, with 10 nodes and 0.06 alpha, FDR at 3%: 0.6719480519480518\n",
      "In testing set, with 10 nodes and 0.06 alpha, FDR at 3%: 0.6857142857142857\n",
      "In training set, with 11 nodes and 0.06 alpha, FDR at 3%: 0.6763636363636364\n",
      "In testing set, with 11 nodes and 0.06 alpha, FDR at 3%: 0.6959183673469388\n",
      "In training set, with 12 nodes and 0.06 alpha, FDR at 3%: 0.6737662337662338\n",
      "In testing set, with 12 nodes and 0.06 alpha, FDR at 3%: 0.6877551020408162\n",
      "In training set, with 13 nodes and 0.06 alpha, FDR at 3%: 0.6711688311688311\n",
      "In testing set, with 13 nodes and 0.06 alpha, FDR at 3%: 0.6653061224489795\n",
      "In training set, with 14 nodes and 0.06 alpha, FDR at 3%: 0.6628571428571429\n",
      "In testing set, with 14 nodes and 0.06 alpha, FDR at 3%: 0.6673469387755102\n",
      "In training set, with 15 nodes and 0.06 alpha, FDR at 3%: 0.6758441558441558\n",
      "In testing set, with 15 nodes and 0.06 alpha, FDR at 3%: 0.710204081632653\n",
      "In training set, with 16 nodes and 0.06 alpha, FDR at 3%: 0.6828571428571429\n",
      "In testing set, with 16 nodes and 0.06 alpha, FDR at 3%: 0.7\n",
      "In training set, with 17 nodes and 0.06 alpha, FDR at 3%: 0.6758441558441558\n",
      "In testing set, with 17 nodes and 0.06 alpha, FDR at 3%: 0.6959183673469388\n",
      "In training set, with 18 nodes and 0.06 alpha, FDR at 3%: 0.6657142857142857\n",
      "In testing set, with 18 nodes and 0.06 alpha, FDR at 3%: 0.7\n",
      "In training set, with 19 nodes and 0.06 alpha, FDR at 3%: 0.6774025974025973\n",
      "In testing set, with 19 nodes and 0.06 alpha, FDR at 3%: 0.6877551020408162\n",
      "In training set, with 20 nodes and 0.06 alpha, FDR at 3%: 0.6797402597402596\n",
      "In testing set, with 20 nodes and 0.06 alpha, FDR at 3%: 0.7163265306122449\n"
     ]
    }
   ],
   "source": [
    "# hidden_layer_size range(5,21,1) & alpha = 0.06\n",
    "\n",
    "for n in range(5,21,1):\n",
    "    fdr_train = 0\n",
    "    fdr_test = 0\n",
    "\n",
    "    for i in range(5):\n",
    "        \n",
    "        kfolds = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "        for train_index, test_index in kfolds.split(data):\n",
    "            y_train = data.iloc[train_index, -1].to_numpy()\n",
    "            y_test = data.iloc[test_index, -1].to_numpy()\n",
    "            x_train = data.iloc[train_index, 0:-1].to_numpy()\n",
    "            x_test = data.iloc[test_index, 0:-1].to_numpy()\n",
    "        \n",
    "        NN = MLPClassifier(\n",
    "            hidden_layer_sizes=(n,),\n",
    "            activation='relu',\n",
    "            learning_rate='adaptive',\n",
    "            max_iter=10000,\n",
    "            learning_rate_init=.01,\n",
    "            alpha=.06)\n",
    "        \n",
    "        NN.fit(x_train,y_train)\n",
    "        \n",
    "        NN_train_pred = NN.predict_proba(x_train)[:,1]\n",
    "        ind = np.argsort(NN_train_pred)\n",
    "        NN_y_train_sorted = np.take_along_axis(y_train, ind, axis=0)\n",
    "        NN_train_pred_sorted = np.take_along_axis(NN_train_pred, ind, axis=0)\n",
    "        NN_y_train_sorted_3per = NN_y_train_sorted[-int(len(NN_y_train_sorted)*0.03):-1]\n",
    "        NN_y_train_sorted_3per_fraud = NN_y_train_sorted_3per[NN_y_train_sorted_3per==1]\n",
    "        y_train_fraud = len(y_train[y_train==1])\n",
    "        fdr_train += len(NN_y_train_sorted_3per_fraud)/y_train_fraud\n",
    "    \n",
    "        NN_test_pred = NN.predict_proba(x_test)[:,1]\n",
    "        ind = np.argsort(NN_test_pred)\n",
    "        NN_y_test_sorted = np.take_along_axis(y_test, ind, axis=0)\n",
    "        NN_test_pred_sorted = np.take_along_axis(NN_test_pred, ind, axis=0)\n",
    "        NN_y_test_sorted_3per = NN_y_test_sorted[-int(len(NN_y_test_sorted)*0.03):-1]\n",
    "        NN_y_test_sorted_3per_fraud = NN_y_test_sorted_3per[NN_y_test_sorted_3per==1]\n",
    "        y_test_fraud = len(y_test[y_test==1])\n",
    "        fdr_test += len(NN_y_test_sorted_3per_fraud)/y_test_fraud\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    avg_fdr_train = fdr_train/5\n",
    "    avg_fdr_test = fdr_test/5\n",
    "\n",
    "    print(f'In training set, with {n} nodes and 0.06 alpha, FDR at 3%:', avg_fdr_train)\n",
    "    print(f'In testing set, with {n} nodes and 0.06 alpha, FDR at 3%:', avg_fdr_test)\n",
    "    \n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In training set, with 5 nodes and 0.08 alpha, FDR at 3%: 0.6605194805194805\n",
      "In testing set, with 5 nodes and 0.08 alpha, FDR at 3%: 0.6714285714285715\n",
      "In training set, with 6 nodes and 0.08 alpha, FDR at 3%: 0.6597402597402597\n",
      "In testing set, with 6 nodes and 0.08 alpha, FDR at 3%: 0.6632653061224489\n",
      "In training set, with 7 nodes and 0.08 alpha, FDR at 3%: 0.6662337662337662\n",
      "In testing set, with 7 nodes and 0.08 alpha, FDR at 3%: 0.6714285714285715\n",
      "In training set, with 8 nodes and 0.08 alpha, FDR at 3%: 0.6685714285714285\n",
      "In testing set, with 8 nodes and 0.08 alpha, FDR at 3%: 0.6836734693877551\n",
      "In training set, with 9 nodes and 0.08 alpha, FDR at 3%: 0.6690909090909091\n",
      "In testing set, with 9 nodes and 0.08 alpha, FDR at 3%: 0.6877551020408164\n",
      "In training set, with 10 nodes and 0.08 alpha, FDR at 3%: 0.6646753246753246\n",
      "In testing set, with 10 nodes and 0.08 alpha, FDR at 3%: 0.6877551020408162\n",
      "In training set, with 11 nodes and 0.08 alpha, FDR at 3%: 0.6690909090909091\n",
      "In testing set, with 11 nodes and 0.08 alpha, FDR at 3%: 0.6795918367346938\n",
      "In training set, with 12 nodes and 0.08 alpha, FDR at 3%: 0.6555844155844156\n",
      "In testing set, with 12 nodes and 0.08 alpha, FDR at 3%: 0.6551020408163265\n",
      "In training set, with 13 nodes and 0.08 alpha, FDR at 3%: 0.6675324675324676\n",
      "In testing set, with 13 nodes and 0.08 alpha, FDR at 3%: 0.6918367346938774\n",
      "In training set, with 14 nodes and 0.08 alpha, FDR at 3%: 0.6703896103896103\n",
      "In testing set, with 14 nodes and 0.08 alpha, FDR at 3%: 0.6857142857142857\n",
      "In training set, with 15 nodes and 0.08 alpha, FDR at 3%: 0.667012987012987\n",
      "In testing set, with 15 nodes and 0.08 alpha, FDR at 3%: 0.6959183673469388\n",
      "In training set, with 16 nodes and 0.08 alpha, FDR at 3%: 0.6696103896103895\n",
      "In testing set, with 16 nodes and 0.08 alpha, FDR at 3%: 0.6795918367346938\n",
      "In training set, with 17 nodes and 0.08 alpha, FDR at 3%: 0.6636363636363637\n",
      "In testing set, with 17 nodes and 0.08 alpha, FDR at 3%: 0.6755102040816326\n",
      "In training set, with 18 nodes and 0.08 alpha, FDR at 3%: 0.6651948051948052\n",
      "In testing set, with 18 nodes and 0.08 alpha, FDR at 3%: 0.6857142857142857\n",
      "In training set, with 19 nodes and 0.08 alpha, FDR at 3%: 0.6628571428571429\n",
      "In testing set, with 19 nodes and 0.08 alpha, FDR at 3%: 0.673469387755102\n",
      "In training set, with 20 nodes and 0.08 alpha, FDR at 3%: 0.6690909090909091\n",
      "In testing set, with 20 nodes and 0.08 alpha, FDR at 3%: 0.6979591836734694\n"
     ]
    }
   ],
   "source": [
    "# hidden_layer_size range(5,21,1) & alpha = 0.08\n",
    "\n",
    "for n in range(5,21,1):\n",
    "    fdr_train = 0\n",
    "    fdr_test = 0\n",
    "\n",
    "    for i in range(5):\n",
    "        \n",
    "        kfolds = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "        for train_index, test_index in kfolds.split(data):\n",
    "            y_train = data.iloc[train_index, -1].to_numpy()\n",
    "            y_test = data.iloc[test_index, -1].to_numpy()\n",
    "            x_train = data.iloc[train_index, 0:-1].to_numpy()\n",
    "            x_test = data.iloc[test_index, 0:-1].to_numpy()\n",
    "        \n",
    "        NN = MLPClassifier(\n",
    "            hidden_layer_sizes=(n,),\n",
    "            activation='relu',\n",
    "            learning_rate='adaptive',\n",
    "            max_iter=10000,\n",
    "            learning_rate_init=.01,\n",
    "            alpha=.08)\n",
    "        \n",
    "        NN.fit(x_train,y_train)\n",
    "        \n",
    "        NN_train_pred = NN.predict_proba(x_train)[:,1]\n",
    "        ind = np.argsort(NN_train_pred)\n",
    "        NN_y_train_sorted = np.take_along_axis(y_train, ind, axis=0)\n",
    "        NN_train_pred_sorted = np.take_along_axis(NN_train_pred, ind, axis=0)\n",
    "        NN_y_train_sorted_3per = NN_y_train_sorted[-int(len(NN_y_train_sorted)*0.03):-1]\n",
    "        NN_y_train_sorted_3per_fraud = NN_y_train_sorted_3per[NN_y_train_sorted_3per==1]\n",
    "        y_train_fraud = len(y_train[y_train==1])\n",
    "        fdr_train += len(NN_y_train_sorted_3per_fraud)/y_train_fraud\n",
    "    \n",
    "        NN_test_pred = NN.predict_proba(x_test)[:,1]\n",
    "        ind = np.argsort(NN_test_pred)\n",
    "        NN_y_test_sorted = np.take_along_axis(y_test, ind, axis=0)\n",
    "        NN_test_pred_sorted = np.take_along_axis(NN_test_pred, ind, axis=0)\n",
    "        NN_y_test_sorted_3per = NN_y_test_sorted[-int(len(NN_y_test_sorted)*0.03):-1]\n",
    "        NN_y_test_sorted_3per_fraud = NN_y_test_sorted_3per[NN_y_test_sorted_3per==1]\n",
    "        y_test_fraud = len(y_test[y_test==1])\n",
    "        fdr_test += len(NN_y_test_sorted_3per_fraud)/y_test_fraud\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    avg_fdr_train = fdr_train/5\n",
    "    avg_fdr_test = fdr_test/5\n",
    "\n",
    "    print(f'In training set, with {n} nodes and 0.08 alpha, FDR at 3%:', avg_fdr_train)\n",
    "    print(f'In testing set, with {n} nodes and 0.08 alpha, FDR at 3%:', avg_fdr_test)\n",
    "    \n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In training set, with 1st 5 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.6854545454545454\n",
      "In testing set, with 1st 5 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.6979591836734695\n",
      "In training set, with 1st 6 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.7420779220779221\n",
      "In testing set, with 1st 6 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.7428571428571429\n",
      "In training set, with 1st 7 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.7402597402597403\n",
      "In testing set, with 1st 7 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.7408163265306122\n",
      "In training set, with 1st 8 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.750909090909091\n",
      "In testing set, with 1st 8 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.753061224489796\n",
      "In training set, with 1st 9 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.7584415584415585\n",
      "In testing set, with 1st 9 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.7510204081632653\n",
      "In training set, with 1st 10 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.7394805194805195\n",
      "In testing set, with 1st 10 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.7306122448979592\n",
      "In training set, with 1st 11 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.7727272727272727\n",
      "In testing set, with 1st 11 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.7755102040816327\n",
      "In training set, with 1st 12 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.7612987012987014\n",
      "In testing set, with 1st 12 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.7673469387755103\n",
      "In training set, with 1st 13 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.7607792207792208\n",
      "In testing set, with 1st 13 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.7408163265306122\n",
      "In training set, with 1st 14 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.7683116883116883\n",
      "In testing set, with 1st 14 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.7857142857142857\n",
      "In training set, with 1st 15 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.7683116883116885\n",
      "In testing set, with 1st 15 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.7775510204081634\n",
      "In training set, with 1st 16 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.782077922077922\n",
      "In testing set, with 1st 16 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.7714285714285715\n",
      "In training set, with 1st 17 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.7828571428571429\n",
      "In testing set, with 1st 17 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.7877551020408162\n",
      "In training set, with 1st 18 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.7818181818181817\n",
      "In testing set, with 1st 18 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.763265306122449\n",
      "In training set, with 1st 19 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.776883116883117\n",
      "In testing set, with 1st 19 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.7653061224489796\n",
      "In training set, with 1st 20 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.7672727272727273\n",
      "In testing set, with 1st 20 nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%: 0.742857142857143\n"
     ]
    }
   ],
   "source": [
    "# 2 layers & hidden_layer_size range(5,11,1) & alpha = 0.01\n",
    "\n",
    "for n in range(5,21,1):\n",
    "    fdr_train = 0\n",
    "    fdr_test = 0\n",
    "        \n",
    "    for i in range(5):\n",
    "\n",
    "        kfolds = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "        for train_index, test_index in kfolds.split(data):\n",
    "            y_train = data.iloc[train_index, -1].to_numpy()\n",
    "            y_test = data.iloc[test_index, -1].to_numpy()\n",
    "            x_train = data.iloc[train_index, 0:-1].to_numpy()\n",
    "            x_test = data.iloc[test_index, 0:-1].to_numpy()\n",
    "\n",
    "        NN = MLPClassifier(\n",
    "            hidden_layer_sizes=(n,5),\n",
    "            activation='relu',\n",
    "            learning_rate='adaptive',\n",
    "            max_iter=10000,\n",
    "            learning_rate_init=.01,\n",
    "            alpha=.01)\n",
    "\n",
    "        NN.fit(x_train,y_train)\n",
    "\n",
    "        NN_train_pred = NN.predict_proba(x_train)[:,1]\n",
    "        ind = np.argsort(NN_train_pred)\n",
    "        NN_y_train_sorted = np.take_along_axis(y_train, ind, axis=0)\n",
    "        NN_train_pred_sorted = np.take_along_axis(NN_train_pred, ind, axis=0)\n",
    "        NN_y_train_sorted_3per = NN_y_train_sorted[-int(len(NN_y_train_sorted)*0.03):-1]\n",
    "        NN_y_train_sorted_3per_fraud = NN_y_train_sorted_3per[NN_y_train_sorted_3per==1]\n",
    "        y_train_fraud = len(y_train[y_train==1])\n",
    "        fdr_train += len(NN_y_train_sorted_3per_fraud)/y_train_fraud\n",
    "\n",
    "        NN_test_pred = NN.predict_proba(x_test)[:,1]\n",
    "        ind = np.argsort(NN_test_pred)\n",
    "        NN_y_test_sorted = np.take_along_axis(y_test, ind, axis=0)\n",
    "        NN_test_pred_sorted = np.take_along_axis(NN_test_pred, ind, axis=0)\n",
    "        NN_y_test_sorted_3per = NN_y_test_sorted[-int(len(NN_y_test_sorted)*0.03):-1]\n",
    "        NN_y_test_sorted_3per_fraud = NN_y_test_sorted_3per[NN_y_test_sorted_3per==1]\n",
    "        y_test_fraud = len(y_test[y_test==1])\n",
    "        fdr_test += len(NN_y_test_sorted_3per_fraud)/y_test_fraud\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    avg_fdr_train = fdr_train/5\n",
    "    avg_fdr_test = fdr_test/5\n",
    "\n",
    "    print(f'In training set, with 1st {n} nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%:', avg_fdr_train)\n",
    "    print(f'In testing set, with 1st {n} nodes, 2nd 5 nodes and 0.01 alpha, FDR at 3%:', avg_fdr_test)\n",
    "\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In training set, with 1st 5 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.6922077922077922\n",
      "In testing set, with 1st 5 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.6979591836734695\n",
      "In training set, with 1st 6 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7431168831168831\n",
      "In testing set, with 1st 6 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.753061224489796\n",
      "In training set, with 1st 7 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7431168831168831\n",
      "In testing set, with 1st 7 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7285714285714285\n",
      "In training set, with 1st 8 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7581818181818182\n",
      "In testing set, with 1st 8 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7489795918367348\n",
      "In training set, with 1st 9 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7457142857142858\n",
      "In testing set, with 1st 9 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7510204081632652\n",
      "In training set, with 1st 10 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7711688311688312\n",
      "In testing set, with 1st 10 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7653061224489796\n",
      "In training set, with 1st 11 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7644155844155844\n",
      "In testing set, with 1st 11 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7755102040816327\n",
      "In training set, with 1st 12 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7646753246753247\n",
      "In testing set, with 1st 12 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7816326530612245\n",
      "In training set, with 1st 13 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7670129870129869\n",
      "In testing set, with 1st 13 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7775510204081633\n",
      "In training set, with 1st 14 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7711688311688312\n",
      "In testing set, with 1st 14 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.773469387755102\n",
      "In training set, with 1st 15 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7722077922077922\n",
      "In testing set, with 1st 15 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7795918367346938\n",
      "In training set, with 1st 16 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7740259740259741\n",
      "In testing set, with 1st 16 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7673469387755103\n",
      "In training set, with 1st 17 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7812987012987013\n",
      "In testing set, with 1st 17 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7836734693877551\n",
      "In training set, with 1st 18 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7657142857142858\n",
      "In testing set, with 1st 18 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7612244897959183\n",
      "In training set, with 1st 19 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7711688311688312\n",
      "In testing set, with 1st 19 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.746938775510204\n",
      "In training set, with 1st 20 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7823376623376623\n",
      "In testing set, with 1st 20 nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%: 0.7755102040816326\n"
     ]
    }
   ],
   "source": [
    "# 2 layers & hidden_layer_size range(5,11,1) & alpha = 0.01\n",
    "\n",
    "for n in range(5,21,1):\n",
    "    fdr_train = 0\n",
    "    fdr_test = 0\n",
    "        \n",
    "    for i in range(5):\n",
    "\n",
    "        kfolds = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "        for train_index, test_index in kfolds.split(data):\n",
    "            y_train = data.iloc[train_index, -1].to_numpy()\n",
    "            y_test = data.iloc[test_index, -1].to_numpy()\n",
    "            x_train = data.iloc[train_index, 0:-1].to_numpy()\n",
    "            x_test = data.iloc[test_index, 0:-1].to_numpy()\n",
    "\n",
    "        NN = MLPClassifier(\n",
    "            hidden_layer_sizes=(n,10),\n",
    "            activation='relu',\n",
    "            learning_rate='adaptive',\n",
    "            max_iter=10000,\n",
    "            learning_rate_init=.01,\n",
    "            alpha=.01)\n",
    "\n",
    "        NN.fit(x_train,y_train)\n",
    "\n",
    "        NN_train_pred = NN.predict_proba(x_train)[:,1]\n",
    "        ind = np.argsort(NN_train_pred)\n",
    "        NN_y_train_sorted = np.take_along_axis(y_train, ind, axis=0)\n",
    "        NN_train_pred_sorted = np.take_along_axis(NN_train_pred, ind, axis=0)\n",
    "        NN_y_train_sorted_3per = NN_y_train_sorted[-int(len(NN_y_train_sorted)*0.03):-1]\n",
    "        NN_y_train_sorted_3per_fraud = NN_y_train_sorted_3per[NN_y_train_sorted_3per==1]\n",
    "        y_train_fraud = len(y_train[y_train==1])\n",
    "        fdr_train += len(NN_y_train_sorted_3per_fraud)/y_train_fraud\n",
    "\n",
    "        NN_test_pred = NN.predict_proba(x_test)[:,1]\n",
    "        ind = np.argsort(NN_test_pred)\n",
    "        NN_y_test_sorted = np.take_along_axis(y_test, ind, axis=0)\n",
    "        NN_test_pred_sorted = np.take_along_axis(NN_test_pred, ind, axis=0)\n",
    "        NN_y_test_sorted_3per = NN_y_test_sorted[-int(len(NN_y_test_sorted)*0.03):-1]\n",
    "        NN_y_test_sorted_3per_fraud = NN_y_test_sorted_3per[NN_y_test_sorted_3per==1]\n",
    "        y_test_fraud = len(y_test[y_test==1])\n",
    "        fdr_test += len(NN_y_test_sorted_3per_fraud)/y_test_fraud\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    avg_fdr_train = fdr_train/5\n",
    "    avg_fdr_test = fdr_test/5\n",
    "\n",
    "    print(f'In training set, with 1st {n} nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%:', avg_fdr_train)\n",
    "    print(f'In testing set, with 1st {n} nodes, 2nd 10 nodes and 0.01 alpha, FDR at 3%:', avg_fdr_test)\n",
    "\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In training set, with 1st 5 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.7083116883116883\n",
      "In testing set, with 1st 5 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.7102040816326531\n",
      "In training set, with 1st 6 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.732987012987013\n",
      "In testing set, with 1st 6 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.746938775510204\n",
      "In training set, with 1st 7 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.7345454545454546\n",
      "In testing set, with 1st 7 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.7428571428571428\n",
      "In training set, with 1st 8 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.7503896103896104\n",
      "In testing set, with 1st 8 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.7693877551020408\n",
      "In training set, with 1st 9 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.7514285714285714\n",
      "In testing set, with 1st 9 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.7489795918367347\n",
      "In training set, with 1st 10 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.7667532467532469\n",
      "In testing set, with 1st 10 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.7551020408163266\n",
      "In training set, with 1st 11 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.7742857142857142\n",
      "In testing set, with 1st 11 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.7836734693877551\n",
      "In training set, with 1st 12 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.7735064935064935\n",
      "In testing set, with 1st 12 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.7693877551020407\n",
      "In training set, with 1st 13 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.7784415584415585\n",
      "In testing set, with 1st 13 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.773469387755102\n",
      "In training set, with 1st 14 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.7735064935064935\n",
      "In testing set, with 1st 14 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.7816326530612245\n",
      "In training set, with 1st 15 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.78\n",
      "In testing set, with 1st 15 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.773469387755102\n",
      "In training set, with 1st 16 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.7828571428571429\n",
      "In testing set, with 1st 16 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.773469387755102\n",
      "In training set, with 1st 17 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.7815584415584416\n",
      "In testing set, with 1st 17 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.7816326530612244\n",
      "In training set, with 1st 18 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.7779220779220779\n",
      "In testing set, with 1st 18 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.753061224489796\n",
      "In training set, with 1st 19 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.791948051948052\n",
      "In testing set, with 1st 19 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.7877551020408162\n",
      "In training set, with 1st 20 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.7755844155844155\n",
      "In testing set, with 1st 20 nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%: 0.7877551020408162\n"
     ]
    }
   ],
   "source": [
    "# 2 layers & hidden_layer_size range(5,11,1) & alpha = 0.01\n",
    "\n",
    "for n in range(5,21,1):\n",
    "    fdr_train = 0\n",
    "    fdr_test = 0\n",
    "        \n",
    "    for i in range(5):\n",
    "\n",
    "        kfolds = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "        for train_index, test_index in kfolds.split(data):\n",
    "            y_train = data.iloc[train_index, -1].to_numpy()\n",
    "            y_test = data.iloc[test_index, -1].to_numpy()\n",
    "            x_train = data.iloc[train_index, 0:-1].to_numpy()\n",
    "            x_test = data.iloc[test_index, 0:-1].to_numpy()\n",
    "\n",
    "        NN = MLPClassifier(\n",
    "            hidden_layer_sizes=(n,15),\n",
    "            activation='relu',\n",
    "            learning_rate='adaptive',\n",
    "            max_iter=10000,\n",
    "            learning_rate_init=.01,\n",
    "            alpha=.01)\n",
    "\n",
    "        NN.fit(x_train,y_train)\n",
    "\n",
    "        NN_train_pred = NN.predict_proba(x_train)[:,1]\n",
    "        ind = np.argsort(NN_train_pred)\n",
    "        NN_y_train_sorted = np.take_along_axis(y_train, ind, axis=0)\n",
    "        NN_train_pred_sorted = np.take_along_axis(NN_train_pred, ind, axis=0)\n",
    "        NN_y_train_sorted_3per = NN_y_train_sorted[-int(len(NN_y_train_sorted)*0.03):-1]\n",
    "        NN_y_train_sorted_3per_fraud = NN_y_train_sorted_3per[NN_y_train_sorted_3per==1]\n",
    "        y_train_fraud = len(y_train[y_train==1])\n",
    "        fdr_train += len(NN_y_train_sorted_3per_fraud)/y_train_fraud\n",
    "\n",
    "        NN_test_pred = NN.predict_proba(x_test)[:,1]\n",
    "        ind = np.argsort(NN_test_pred)\n",
    "        NN_y_test_sorted = np.take_along_axis(y_test, ind, axis=0)\n",
    "        NN_test_pred_sorted = np.take_along_axis(NN_test_pred, ind, axis=0)\n",
    "        NN_y_test_sorted_3per = NN_y_test_sorted[-int(len(NN_y_test_sorted)*0.03):-1]\n",
    "        NN_y_test_sorted_3per_fraud = NN_y_test_sorted_3per[NN_y_test_sorted_3per==1]\n",
    "        y_test_fraud = len(y_test[y_test==1])\n",
    "        fdr_test += len(NN_y_test_sorted_3per_fraud)/y_test_fraud\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    avg_fdr_train = fdr_train/5\n",
    "    avg_fdr_test = fdr_test/5\n",
    "\n",
    "    print(f'In training set, with 1st {n} nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%:', avg_fdr_train)\n",
    "    print(f'In testing set, with 1st {n} nodes, 2nd 15 nodes and 0.01 alpha, FDR at 3%:', avg_fdr_test)\n",
    "\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In training set, with 1st 5 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.7363636363636363\n",
      "In testing set, with 1st 5 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.7285714285714285\n",
      "In training set, with 1st 6 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.7150649350649351\n",
      "In testing set, with 1st 6 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.7428571428571429\n",
      "In training set, with 1st 7 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.7519480519480519\n",
      "In testing set, with 1st 7 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.7489795918367348\n",
      "In training set, with 1st 8 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.7592207792207792\n",
      "In testing set, with 1st 8 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.7653061224489794\n",
      "In training set, with 1st 9 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.7548051948051947\n",
      "In testing set, with 1st 9 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.7571428571428572\n",
      "In training set, with 1st 10 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.7555844155844156\n",
      "In testing set, with 1st 10 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.7387755102040817\n",
      "In training set, with 1st 11 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.7618181818181818\n",
      "In testing set, with 1st 11 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.7612244897959184\n",
      "In training set, with 1st 12 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.7810389610389612\n",
      "In testing set, with 1st 12 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.7836734693877552\n",
      "In training set, with 1st 13 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.7651948051948052\n",
      "In testing set, with 1st 13 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.7755102040816326\n",
      "In training set, with 1st 14 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.7838961038961039\n",
      "In testing set, with 1st 14 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.7673469387755102\n",
      "In training set, with 1st 15 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.7787012987012988\n",
      "In testing set, with 1st 15 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.7857142857142856\n",
      "In training set, with 1st 16 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.7693506493506493\n",
      "In testing set, with 1st 16 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.773469387755102\n",
      "In training set, with 1st 17 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.7690909090909092\n",
      "In testing set, with 1st 17 nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%: 0.7714285714285714\n"
     ]
    }
   ],
   "source": [
    "# 2 layers & hidden_layer_size range(5,11,1) & alpha = 0.01\n",
    "\n",
    "for n in range(5,21,1):\n",
    "    fdr_train = 0\n",
    "    fdr_test = 0\n",
    "        \n",
    "    for i in range(5):\n",
    "\n",
    "        kfolds = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "        for train_index, test_index in kfolds.split(data):\n",
    "            y_train = data.iloc[train_index, -1].to_numpy()\n",
    "            y_test = data.iloc[test_index, -1].to_numpy()\n",
    "            x_train = data.iloc[train_index, 0:-1].to_numpy()\n",
    "            x_test = data.iloc[test_index, 0:-1].to_numpy()\n",
    "\n",
    "        NN = MLPClassifier(\n",
    "            hidden_layer_sizes=(n,20),\n",
    "            activation='relu',\n",
    "            learning_rate='adaptive',\n",
    "            max_iter=10000,\n",
    "            learning_rate_init=.01,\n",
    "            alpha=.01)\n",
    "\n",
    "        NN.fit(x_train,y_train)\n",
    "\n",
    "        NN_train_pred = NN.predict_proba(x_train)[:,1]\n",
    "        ind = np.argsort(NN_train_pred)\n",
    "        NN_y_train_sorted = np.take_along_axis(y_train, ind, axis=0)\n",
    "        NN_train_pred_sorted = np.take_along_axis(NN_train_pred, ind, axis=0)\n",
    "        NN_y_train_sorted_3per = NN_y_train_sorted[-int(len(NN_y_train_sorted)*0.03):-1]\n",
    "        NN_y_train_sorted_3per_fraud = NN_y_train_sorted_3per[NN_y_train_sorted_3per==1]\n",
    "        y_train_fraud = len(y_train[y_train==1])\n",
    "        fdr_train += len(NN_y_train_sorted_3per_fraud)/y_train_fraud\n",
    "\n",
    "        NN_test_pred = NN.predict_proba(x_test)[:,1]\n",
    "        ind = np.argsort(NN_test_pred)\n",
    "        NN_y_test_sorted = np.take_along_axis(y_test, ind, axis=0)\n",
    "        NN_test_pred_sorted = np.take_along_axis(NN_test_pred, ind, axis=0)\n",
    "        NN_y_test_sorted_3per = NN_y_test_sorted[-int(len(NN_y_test_sorted)*0.03):-1]\n",
    "        NN_y_test_sorted_3per_fraud = NN_y_test_sorted_3per[NN_y_test_sorted_3per==1]\n",
    "        y_test_fraud = len(y_test[y_test==1])\n",
    "        fdr_test += len(NN_y_test_sorted_3per_fraud)/y_test_fraud\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    avg_fdr_train = fdr_train/5\n",
    "    avg_fdr_test = fdr_test/5\n",
    "\n",
    "    print(f'In training set, with 1st {n} nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%:', avg_fdr_train)\n",
    "    print(f'In testing set, with 1st {n} nodes, 2nd 20 nodes and 0.01 alpha, FDR at 3%:', avg_fdr_test)\n",
    "\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In training set, with 1st 5 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.6483116883116884\n",
      "In testing set, with 1st 5 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.6653061224489796\n",
      "In training set, with 1st 6 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.6714285714285714\n",
      "In testing set, with 1st 6 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.6979591836734694\n",
      "In training set, with 1st 7 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.6664935064935066\n",
      "In testing set, with 1st 7 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.673469387755102\n",
      "In training set, with 1st 8 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.6745454545454546\n",
      "In testing set, with 1st 8 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.7163265306122449\n",
      "In training set, with 1st 9 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.6766233766233766\n",
      "In testing set, with 1st 9 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.6979591836734694\n",
      "In training set, with 1st 10 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.688051948051948\n",
      "In testing set, with 1st 10 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.7183673469387755\n",
      "In training set, with 1st 11 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.6672727272727272\n",
      "In testing set, with 1st 11 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.6836734693877552\n",
      "In training set, with 1st 12 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.6696103896103895\n",
      "In testing set, with 1st 12 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.6918367346938774\n",
      "In training set, with 1st 13 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.6812987012987012\n",
      "In testing set, with 1st 13 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.7183673469387755\n",
      "In training set, with 1st 14 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.6857142857142857\n",
      "In testing set, with 1st 14 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.7\n",
      "In training set, with 1st 15 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.6784415584415584\n",
      "In testing set, with 1st 15 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.710204081632653\n",
      "In training set, with 1st 16 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.6625974025974026\n",
      "In testing set, with 1st 16 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.6836734693877551\n",
      "In training set, with 1st 17 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.6799999999999999\n",
      "In testing set, with 1st 17 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.6979591836734695\n",
      "In training set, with 1st 18 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.6732467532467533\n",
      "In testing set, with 1st 18 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.6938775510204083\n",
      "In training set, with 1st 19 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.6781818181818182\n",
      "In testing set, with 1st 19 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.6938775510204082\n",
      "In training set, with 1st 20 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.6753246753246753\n",
      "In testing set, with 1st 20 nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "# 2 layers & hidden_layer_size range(5,11,1) & alpha = 0.01\n",
    "\n",
    "for n in range(5,21,1):\n",
    "    fdr_train = 0\n",
    "    fdr_test = 0\n",
    "        \n",
    "    for i in range(5):\n",
    "\n",
    "        kfolds = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "        for train_index, test_index in kfolds.split(data):\n",
    "            y_train = data.iloc[train_index, -1].to_numpy()\n",
    "            y_test = data.iloc[test_index, -1].to_numpy()\n",
    "            x_train = data.iloc[train_index, 0:-1].to_numpy()\n",
    "            x_test = data.iloc[test_index, 0:-1].to_numpy()\n",
    "\n",
    "        NN = MLPClassifier(\n",
    "            hidden_layer_sizes=(n,5),\n",
    "            activation='relu',\n",
    "            learning_rate='adaptive',\n",
    "            max_iter=10000,\n",
    "            learning_rate_init=.01,\n",
    "            alpha=.1)\n",
    "\n",
    "        NN.fit(x_train,y_train)\n",
    "\n",
    "        NN_train_pred = NN.predict_proba(x_train)[:,1]\n",
    "        ind = np.argsort(NN_train_pred)\n",
    "        NN_y_train_sorted = np.take_along_axis(y_train, ind, axis=0)\n",
    "        NN_train_pred_sorted = np.take_along_axis(NN_train_pred, ind, axis=0)\n",
    "        NN_y_train_sorted_3per = NN_y_train_sorted[-int(len(NN_y_train_sorted)*0.03):-1]\n",
    "        NN_y_train_sorted_3per_fraud = NN_y_train_sorted_3per[NN_y_train_sorted_3per==1]\n",
    "        y_train_fraud = len(y_train[y_train==1])\n",
    "        fdr_train += len(NN_y_train_sorted_3per_fraud)/y_train_fraud\n",
    "\n",
    "        NN_test_pred = NN.predict_proba(x_test)[:,1]\n",
    "        ind = np.argsort(NN_test_pred)\n",
    "        NN_y_test_sorted = np.take_along_axis(y_test, ind, axis=0)\n",
    "        NN_test_pred_sorted = np.take_along_axis(NN_test_pred, ind, axis=0)\n",
    "        NN_y_test_sorted_3per = NN_y_test_sorted[-int(len(NN_y_test_sorted)*0.03):-1]\n",
    "        NN_y_test_sorted_3per_fraud = NN_y_test_sorted_3per[NN_y_test_sorted_3per==1]\n",
    "        y_test_fraud = len(y_test[y_test==1])\n",
    "        fdr_test += len(NN_y_test_sorted_3per_fraud)/y_test_fraud\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    avg_fdr_train = fdr_train/5\n",
    "    avg_fdr_test = fdr_test/5\n",
    "\n",
    "    print(f'In training set, with 1st {n} nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%:', avg_fdr_train)\n",
    "    print(f'In testing set, with 1st {n} nodes, 2nd 5 nodes and 0.1 alpha, FDR at 3%:', avg_fdr_test)\n",
    "\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In training set, with 1st 5 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.6724675324675324\n",
      "In testing set, with 1st 5 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.6938775510204083\n",
      "In training set, with 1st 6 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.655064935064935\n",
      "In testing set, with 1st 6 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.673469387755102\n",
      "In training set, with 1st 7 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.6532467532467533\n",
      "In testing set, with 1st 7 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.6632653061224489\n",
      "In training set, with 1st 8 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.6607792207792207\n",
      "In testing set, with 1st 8 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.6755102040816326\n",
      "In training set, with 1st 9 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.6696103896103895\n",
      "In testing set, with 1st 9 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.7020408163265306\n",
      "In training set, with 1st 10 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.6696103896103895\n",
      "In testing set, with 1st 10 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.6836734693877551\n",
      "In training set, with 1st 11 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.6761038961038961\n",
      "In testing set, with 1st 11 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.6918367346938775\n",
      "In training set, with 1st 12 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.6644155844155843\n",
      "In testing set, with 1st 12 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.6836734693877551\n",
      "In training set, with 1st 13 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.6810389610389611\n",
      "In testing set, with 1st 13 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.7040816326530612\n",
      "In training set, with 1st 14 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.675064935064935\n",
      "In testing set, with 1st 14 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.7\n",
      "In training set, with 1st 15 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.665974025974026\n",
      "In testing set, with 1st 15 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.6857142857142856\n",
      "In training set, with 1st 16 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.6787012987012987\n",
      "In testing set, with 1st 16 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.7224489795918367\n",
      "In training set, with 1st 17 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.6867532467532467\n",
      "In testing set, with 1st 17 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.7306122448979592\n",
      "In training set, with 1st 18 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.6890909090909092\n",
      "In testing set, with 1st 18 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.6979591836734693\n",
      "In training set, with 1st 19 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.6758441558441558\n",
      "In testing set, with 1st 19 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.7081632653061225\n",
      "In training set, with 1st 20 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.6714285714285714\n",
      "In testing set, with 1st 20 nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%: 0.6857142857142857\n"
     ]
    }
   ],
   "source": [
    "# 2 layers & hidden_layer_size range(5,11,1) & alpha = 0.01\n",
    "\n",
    "for n in range(5,21,1):\n",
    "    fdr_train = 0\n",
    "    fdr_test = 0\n",
    "        \n",
    "    for i in range(5):\n",
    "\n",
    "        kfolds = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "        for train_index, test_index in kfolds.split(data):\n",
    "            y_train = data.iloc[train_index, -1].to_numpy()\n",
    "            y_test = data.iloc[test_index, -1].to_numpy()\n",
    "            x_train = data.iloc[train_index, 0:-1].to_numpy()\n",
    "            x_test = data.iloc[test_index, 0:-1].to_numpy()\n",
    "\n",
    "        NN = MLPClassifier(\n",
    "            hidden_layer_sizes=(n,10),\n",
    "            activation='relu',\n",
    "            learning_rate='adaptive',\n",
    "            max_iter=10000,\n",
    "            learning_rate_init=.01,\n",
    "            alpha=.1)\n",
    "\n",
    "        NN.fit(x_train,y_train)\n",
    "\n",
    "        NN_train_pred = NN.predict_proba(x_train)[:,1]\n",
    "        ind = np.argsort(NN_train_pred)\n",
    "        NN_y_train_sorted = np.take_along_axis(y_train, ind, axis=0)\n",
    "        NN_train_pred_sorted = np.take_along_axis(NN_train_pred, ind, axis=0)\n",
    "        NN_y_train_sorted_3per = NN_y_train_sorted[-int(len(NN_y_train_sorted)*0.03):-1]\n",
    "        NN_y_train_sorted_3per_fraud = NN_y_train_sorted_3per[NN_y_train_sorted_3per==1]\n",
    "        y_train_fraud = len(y_train[y_train==1])\n",
    "        fdr_train += len(NN_y_train_sorted_3per_fraud)/y_train_fraud\n",
    "\n",
    "        NN_test_pred = NN.predict_proba(x_test)[:,1]\n",
    "        ind = np.argsort(NN_test_pred)\n",
    "        NN_y_test_sorted = np.take_along_axis(y_test, ind, axis=0)\n",
    "        NN_test_pred_sorted = np.take_along_axis(NN_test_pred, ind, axis=0)\n",
    "        NN_y_test_sorted_3per = NN_y_test_sorted[-int(len(NN_y_test_sorted)*0.03):-1]\n",
    "        NN_y_test_sorted_3per_fraud = NN_y_test_sorted_3per[NN_y_test_sorted_3per==1]\n",
    "        y_test_fraud = len(y_test[y_test==1])\n",
    "        fdr_test += len(NN_y_test_sorted_3per_fraud)/y_test_fraud\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    avg_fdr_train = fdr_train/5\n",
    "    avg_fdr_test = fdr_test/5\n",
    "\n",
    "    print(f'In training set, with 1st {n} nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%:', avg_fdr_train)\n",
    "    print(f'In testing set, with 1st {n} nodes, 2nd 10 nodes and 0.1 alpha, FDR at 3%:', avg_fdr_test)\n",
    "\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In training set, with 1st 5 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.6483116883116883\n",
      "In testing set, with 1st 5 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.6653061224489796\n",
      "In training set, with 1st 6 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.6584415584415585\n",
      "In testing set, with 1st 6 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.6877551020408162\n",
      "In training set, with 1st 7 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.6690909090909091\n",
      "In testing set, with 1st 7 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.6979591836734694\n",
      "In training set, with 1st 8 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.6664935064935065\n",
      "In testing set, with 1st 8 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.7081632653061224\n",
      "In training set, with 1st 9 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.6846753246753245\n",
      "In testing set, with 1st 9 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.6938775510204083\n",
      "In training set, with 1st 10 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.6807792207792207\n",
      "In testing set, with 1st 10 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.7081632653061225\n",
      "In training set, with 1st 11 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.6709090909090909\n",
      "In testing set, with 1st 11 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.7081632653061225\n",
      "In training set, with 1st 12 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.6768831168831169\n",
      "In testing set, with 1st 12 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.7142857142857142\n",
      "In training set, with 1st 13 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.6906493506493506\n",
      "In testing set, with 1st 13 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.7326530612244897\n",
      "In training set, with 1st 14 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.6812987012987013\n",
      "In testing set, with 1st 14 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.7061224489795918\n",
      "In training set, with 1st 15 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.6716883116883118\n",
      "In testing set, with 1st 15 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.7244897959183674\n",
      "In training set, with 1st 16 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.6797402597402598\n",
      "In testing set, with 1st 16 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.7040816326530612\n",
      "In training set, with 1st 17 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.6794805194805194\n",
      "In testing set, with 1st 17 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.7020408163265306\n",
      "In training set, with 1st 18 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.6815584415584415\n",
      "In testing set, with 1st 18 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.7\n",
      "In training set, with 1st 19 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.6771428571428572\n",
      "In testing set, with 1st 19 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.7\n",
      "In training set, with 1st 20 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.6711688311688311\n",
      "In testing set, with 1st 20 nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%: 0.6979591836734693\n"
     ]
    }
   ],
   "source": [
    "# 2 layers & hidden_layer_size range(5,11,1) & alpha = 0.01\n",
    "\n",
    "for n in range(5,21,1):\n",
    "    fdr_train = 0\n",
    "    fdr_test = 0\n",
    "        \n",
    "    for i in range(5):\n",
    "\n",
    "        kfolds = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "        for train_index, test_index in kfolds.split(data):\n",
    "            y_train = data.iloc[train_index, -1].to_numpy()\n",
    "            y_test = data.iloc[test_index, -1].to_numpy()\n",
    "            x_train = data.iloc[train_index, 0:-1].to_numpy()\n",
    "            x_test = data.iloc[test_index, 0:-1].to_numpy()\n",
    "\n",
    "        NN = MLPClassifier(\n",
    "            hidden_layer_sizes=(n,15),\n",
    "            activation='relu',\n",
    "            learning_rate='adaptive',\n",
    "            max_iter=10000,\n",
    "            learning_rate_init=.01,\n",
    "            alpha=.1)\n",
    "\n",
    "        NN.fit(x_train,y_train)\n",
    "\n",
    "        NN_train_pred = NN.predict_proba(x_train)[:,1]\n",
    "        ind = np.argsort(NN_train_pred)\n",
    "        NN_y_train_sorted = np.take_along_axis(y_train, ind, axis=0)\n",
    "        NN_train_pred_sorted = np.take_along_axis(NN_train_pred, ind, axis=0)\n",
    "        NN_y_train_sorted_3per = NN_y_train_sorted[-int(len(NN_y_train_sorted)*0.03):-1]\n",
    "        NN_y_train_sorted_3per_fraud = NN_y_train_sorted_3per[NN_y_train_sorted_3per==1]\n",
    "        y_train_fraud = len(y_train[y_train==1])\n",
    "        fdr_train += len(NN_y_train_sorted_3per_fraud)/y_train_fraud\n",
    "\n",
    "        NN_test_pred = NN.predict_proba(x_test)[:,1]\n",
    "        ind = np.argsort(NN_test_pred)\n",
    "        NN_y_test_sorted = np.take_along_axis(y_test, ind, axis=0)\n",
    "        NN_test_pred_sorted = np.take_along_axis(NN_test_pred, ind, axis=0)\n",
    "        NN_y_test_sorted_3per = NN_y_test_sorted[-int(len(NN_y_test_sorted)*0.03):-1]\n",
    "        NN_y_test_sorted_3per_fraud = NN_y_test_sorted_3per[NN_y_test_sorted_3per==1]\n",
    "        y_test_fraud = len(y_test[y_test==1])\n",
    "        fdr_test += len(NN_y_test_sorted_3per_fraud)/y_test_fraud\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    avg_fdr_train = fdr_train/5\n",
    "    avg_fdr_test = fdr_test/5\n",
    "\n",
    "    print(f'In training set, with 1st {n} nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%:', avg_fdr_train)\n",
    "    print(f'In testing set, with 1st {n} nodes, 2nd 15 nodes and 0.1 alpha, FDR at 3%:', avg_fdr_test)\n",
    "\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In training set, with 1st 5 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.6561038961038961\n",
      "In testing set, with 1st 5 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.6795918367346939\n",
      "In training set, with 1st 6 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.6581818181818182\n",
      "In testing set, with 1st 6 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.6693877551020407\n",
      "In training set, with 1st 7 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.6683116883116884\n",
      "In testing set, with 1st 7 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.7020408163265306\n",
      "In training set, with 1st 8 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.6851948051948051\n",
      "In testing set, with 1st 8 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.7183673469387756\n",
      "In training set, with 1st 9 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.6844155844155844\n",
      "In testing set, with 1st 9 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.726530612244898\n",
      "In training set, with 1st 10 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.6823376623376622\n",
      "In testing set, with 1st 10 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.6918367346938776\n",
      "In training set, with 1st 11 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.6696103896103895\n",
      "In testing set, with 1st 11 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.6795918367346939\n",
      "In training set, with 1st 12 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.7005194805194804\n",
      "In testing set, with 1st 12 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.7387755102040815\n",
      "In training set, with 1st 13 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.6825974025974025\n",
      "In testing set, with 1st 13 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.7020408163265307\n",
      "In training set, with 1st 14 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.6742857142857143\n",
      "In testing set, with 1st 14 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.6959183673469387\n",
      "In training set, with 1st 15 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.6875324675324676\n",
      "In testing set, with 1st 15 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.7163265306122449\n",
      "In training set, with 1st 16 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.6753246753246753\n",
      "In testing set, with 1st 16 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.7122448979591838\n",
      "In training set, with 1st 17 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.6838961038961038\n",
      "In testing set, with 1st 17 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.7142857142857143\n",
      "In training set, with 1st 18 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.6784415584415584\n",
      "In testing set, with 1st 18 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.7040816326530613\n",
      "In training set, with 1st 19 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.6766233766233766\n",
      "In testing set, with 1st 19 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.7061224489795919\n",
      "In training set, with 1st 20 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.68\n",
      "In testing set, with 1st 20 nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%: 0.7142857142857142\n"
     ]
    }
   ],
   "source": [
    "# 2 layers & hidden_layer_size range(5,11,1) & alpha = 0.01\n",
    "\n",
    "for n in range(5,21,1):\n",
    "    fdr_train = 0\n",
    "    fdr_test = 0\n",
    "        \n",
    "    for i in range(5):\n",
    "\n",
    "        kfolds = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "        for train_index, test_index in kfolds.split(data):\n",
    "            y_train = data.iloc[train_index, -1].to_numpy()\n",
    "            y_test = data.iloc[test_index, -1].to_numpy()\n",
    "            x_train = data.iloc[train_index, 0:-1].to_numpy()\n",
    "            x_test = data.iloc[test_index, 0:-1].to_numpy()\n",
    "\n",
    "        NN = MLPClassifier(\n",
    "            hidden_layer_sizes=(n,20),\n",
    "            activation='relu',\n",
    "            learning_rate='adaptive',\n",
    "            max_iter=10000,\n",
    "            learning_rate_init=.01,\n",
    "            alpha=.1)\n",
    "\n",
    "        NN.fit(x_train,y_train)\n",
    "\n",
    "        NN_train_pred = NN.predict_proba(x_train)[:,1]\n",
    "        ind = np.argsort(NN_train_pred)\n",
    "        NN_y_train_sorted = np.take_along_axis(y_train, ind, axis=0)\n",
    "        NN_train_pred_sorted = np.take_along_axis(NN_train_pred, ind, axis=0)\n",
    "        NN_y_train_sorted_3per = NN_y_train_sorted[-int(len(NN_y_train_sorted)*0.03):-1]\n",
    "        NN_y_train_sorted_3per_fraud = NN_y_train_sorted_3per[NN_y_train_sorted_3per==1]\n",
    "        y_train_fraud = len(y_train[y_train==1])\n",
    "        fdr_train += len(NN_y_train_sorted_3per_fraud)/y_train_fraud\n",
    "\n",
    "        NN_test_pred = NN.predict_proba(x_test)[:,1]\n",
    "        ind = np.argsort(NN_test_pred)\n",
    "        NN_y_test_sorted = np.take_along_axis(y_test, ind, axis=0)\n",
    "        NN_test_pred_sorted = np.take_along_axis(NN_test_pred, ind, axis=0)\n",
    "        NN_y_test_sorted_3per = NN_y_test_sorted[-int(len(NN_y_test_sorted)*0.03):-1]\n",
    "        NN_y_test_sorted_3per_fraud = NN_y_test_sorted_3per[NN_y_test_sorted_3per==1]\n",
    "        y_test_fraud = len(y_test[y_test==1])\n",
    "        fdr_test += len(NN_y_test_sorted_3per_fraud)/y_test_fraud\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    avg_fdr_train = fdr_train/5\n",
    "    avg_fdr_test = fdr_test/5\n",
    "\n",
    "    print(f'In training set, with 1st {n} nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%:', avg_fdr_train)\n",
    "    print(f'In testing set, with 1st {n} nodes, 2nd 20 nodes and 0.1 alpha, FDR at 3%:', avg_fdr_test)\n",
    "\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
